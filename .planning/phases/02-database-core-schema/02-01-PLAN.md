---
phase: 02-database-core-schema
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - supabase/config.toml
  - supabase/migrations/YYYYMMDDHHMMSS_create_core_schema.sql
  - .gitignore
autonomous: true

must_haves:
  truths:
    - "Listings table exists with all required fields (address, city, price, rooms, size, floor, photos, sources, description, contact_info)"
    - "Dedupe hashes table exists with content_hash and listing_id columns"
    - "RLS policies allow public read-only access to both tables"
    - "Indexes exist for common queries (city, price, created_at, sources)"
    - "Updated_at trigger automatically maintains timestamp"
  artifacts:
    - path: "supabase/config.toml"
      provides: "Supabase project configuration"
      min_lines: 10
    - path: "supabase/migrations/YYYYMMDDHHMMSS_create_core_schema.sql"
      provides: "Database schema DDL with tables, indexes, RLS policies"
      min_lines: 80
      contains: ["create table public.listings", "create table public.dedupe_hashes", "enable row level security"]
  key_links:
    - from: "supabase/migrations/*.sql"
      to: "Supabase database"
      via: "supabase db push"
      pattern: "create table public\\.(listings|dedupe_hashes)"
    - from: "public.dedupe_hashes"
      to: "public.listings"
      via: "foreign key constraint"
      pattern: "references public\\.listings\\(id\\)"
---

<objective>
Initialize Supabase migration infrastructure and create core database schema with listings, deduplication hashes, and Row Level Security policies.

Purpose: Establish the database foundation for storing rental listings from multiple platforms with deduplication support, Hebrew text handling, and public read-only access.

Output: Supabase migrations directory with core schema DDL file ready to deploy.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-database-core-schema/02-RESEARCH.md
@src/lib/supabase.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Initialize Supabase migrations infrastructure</name>
  <files>
    supabase/config.toml
    supabase/.gitignore
    .gitignore
  </files>
  <action>
    Run `supabase init` to create local Supabase project structure with migrations directory. This creates:
    - `supabase/config.toml` - Project configuration
    - `supabase/migrations/` - Directory for timestamped SQL files
    - `supabase/.gitignore` - Ignore patterns for local dev files

    Update root `.gitignore` to exclude Supabase local development artifacts (add `supabase/.branches`, `supabase/.temp`, `supabase/functions/`, `supabase/seed.sql` if not already ignored by supabase/.gitignore).

    Do NOT run `supabase start` (requires Docker and not needed for remote-only development). Do NOT link to remote project yet (will be done during deployment).
  </action>
  <verify>
    - Run `ls -la supabase/` and confirm directories exist: `migrations/`, `config.toml`
    - Run `cat supabase/config.toml` and confirm valid TOML configuration
    - Run `cat .gitignore` and confirm Supabase artifacts are ignored
  </verify>
  <done>
    supabase/ directory exists with config.toml and migrations/ folder, ready for migration files.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create core schema migration with listings and dedupe_hashes tables</name>
  <files>
    supabase/migrations/YYYYMMDDHHMMSS_create_core_schema.sql
  </files>
  <action>
    Create a new migration file using `supabase migration new create_core_schema`. This generates a timestamped file like `20260213120000_create_core_schema.sql`.

    Write the migration with four sections (use comments to separate):

    **1. TABLES:**

    Create `public.listings` table with columns:
    - id: uuid primary key default gen_random_uuid()
    - address: text not null
    - city: text not null
    - price: integer not null check (price > 0)
    - rooms: numeric(3,1) check (rooms > 0)
    - size_sqm: integer check (size_sqm > 0)
    - floor: integer
    - photos: jsonb not null default '[]'::jsonb
    - sources: jsonb not null default '[]'::jsonb  (stores array of {platform, url, scraped_at})
    - description: text
    - contact_info: text
    - created_at: timestamptz not null default now()
    - updated_at: timestamptz not null default now()

    Create `public.dedupe_hashes` table with columns:
    - id: uuid primary key default gen_random_uuid()
    - listing_id: uuid not null references public.listings(id) on delete cascade
    - content_hash: text not null check (length(content_hash) = 64)  (SHA-256 = 64 hex chars)
    - created_at: timestamptz not null default now()
    - constraint unique_content_hash unique (content_hash)

    **2. INDEXES:**

    For listings table:
    - create index idx_listings_city on public.listings(city);
    - create index idx_listings_price on public.listings(price);
    - create index idx_listings_created_at on public.listings(created_at desc);
    - create index idx_listings_sources on public.listings using gin(sources);

    For dedupe_hashes table:
    - create index idx_dedupe_hashes_content_hash on public.dedupe_hashes(content_hash);
    - create index idx_dedupe_hashes_listing_id on public.dedupe_hashes(listing_id);

    **3. ROW LEVEL SECURITY:**

    Enable RLS on both tables:
    - alter table public.listings enable row level security;
    - alter table public.dedupe_hashes enable row level security;

    Create public read policies (anon role can SELECT):
    - create policy "Public can read all listings" on public.listings for select to anon using (true);
    - create policy "Public can read dedupe hashes" on public.dedupe_hashes for select to anon using (true);

    Note: service_role bypasses RLS by default, no explicit write policies needed.

    **4. TRIGGERS:**

    Create trigger function to auto-update updated_at timestamp:
    ```sql
    create or replace function public.handle_updated_at()
    returns trigger as $$
    begin
      new.updated_at = now();
      return new;
    end;
    $$ language plpgsql;

    create trigger set_updated_at
      before update on public.listings
      for each row
      execute function public.handle_updated_at();
    ```

    **5. COMMENTS (documentation):**

    - comment on table public.listings is 'Rental listings aggregated from multiple platforms across Israel';
    - comment on column public.listings.sources is 'JSONB array of source objects with platform, url, and scraped_at timestamp';
    - comment on column public.listings.photos is 'JSONB array of photo URLs';
    - comment on table public.dedupe_hashes is 'SHA-256 content hashes for listing deduplication across platforms';
    - comment on column public.dedupe_hashes.content_hash is 'SHA-256 hash of normalized listing data (address, city, price, rooms, size, floor)';

    Use the exact patterns from 02-RESEARCH.md. Do NOT add lat/lng columns (deferred to later phases per research Open Questions #1).
  </action>
  <verify>
    - Run `cat supabase/migrations/*_create_core_schema.sql` and confirm all sections present
    - Run `grep -c "create table" supabase/migrations/*_create_core_schema.sql` and confirm output is 2 (listings + dedupe_hashes)
    - Run `grep -c "create index" supabase/migrations/*_create_core_schema.sql` and confirm output is 6
    - Run `grep -c "enable row level security" supabase/migrations/*_create_core_schema.sql` and confirm output is 2
    - Run `grep -c "create policy" supabase/migrations/*_create_core_schema.sql` and confirm output is 2
    - Run `grep "create trigger" supabase/migrations/*_create_core_schema.sql` and confirm updated_at trigger exists
  </verify>
  <done>
    Migration file exists with complete schema DDL including tables, indexes, RLS policies, updated_at trigger, and documentation comments. File follows research recommendations exactly.
  </done>
</task>

</tasks>

<verification>
After completing both tasks:
1. Supabase migrations infrastructure is initialized (`supabase/` directory exists)
2. Migration file exists with timestamped name
3. Schema includes listings table with all required fields (address, city, price, rooms, size_sqm, floor, photos, sources, description, contact_info, timestamps)
4. Schema includes dedupe_hashes table with listing_id foreign key and content_hash unique constraint
5. RLS is enabled on both tables with public read policies
6. Indexes are created for common query patterns
7. Updated_at trigger is configured
8. Migration is ready to deploy (but not yet pushed to remote)
</verification>

<success_criteria>
**Measurable completion:**
1. `supabase/` directory exists with valid config.toml
2. `supabase/migrations/` directory contains exactly 1 migration file
3. Migration file is valid SQL with no syntax errors
4. Migration file contains both table definitions with all required columns
5. Migration file contains all 6 indexes
6. Migration file enables RLS and creates 2 read policies
7. Migration file includes updated_at trigger function and trigger
8. Root .gitignore excludes Supabase local dev artifacts
</success_criteria>

<output>
After completion, create `.planning/phases/02-database-core-schema/02-01-SUMMARY.md` documenting:
- Migration file location and timestamp
- Table schemas created (columns, types, constraints)
- RLS policies configured
- Indexes added
- Any deviations from research recommendations
</output>
