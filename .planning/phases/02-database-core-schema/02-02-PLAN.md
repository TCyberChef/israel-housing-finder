---
phase: 02-database-core-schema
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified: []
autonomous: false
user_setup:
  - service: supabase
    why: "Database deployment and verification"
    env_vars:
      - name: VITE_SUPABASE_URL
        source: "Supabase Dashboard -> Project Settings -> API -> Project URL"
      - name: VITE_SUPABASE_PUBLISHABLE_KEY
        source: "Supabase Dashboard -> Project Settings -> API -> Project API keys -> anon public"
      - name: SUPABASE_SERVICE_ROLE_KEY
        source: "Supabase Dashboard -> Project Settings -> API -> Project API keys -> service_role (keep secret, never commit)"
    dashboard_config:
      - task: "Note project reference ID"
        location: "Supabase Dashboard -> Project Settings -> General -> Reference ID"

must_haves:
  truths:
    - "Migration is applied to remote Supabase database"
    - "Hebrew text stores and retrieves without encoding corruption"
    - "Public read-only access works with anon key"
    - "Service role can write data successfully"
    - "Source attribution JSONB structure stores multiple platforms"
  artifacts:
    - path: "supabase/migrations/YYYYMMDDHHMMSS_create_core_schema.sql"
      provides: "Applied migration (from 02-01)"
      status: "deployed"
  key_links:
    - from: "src/lib/supabase.ts client"
      to: "remote Supabase database"
      via: "anon key read access"
      pattern: "createClient.*VITE_SUPABASE_URL"
    - from: "service_role key"
      to: "remote Supabase database"
      via: "write access for scrapers"
      pattern: "service.*role"
---

<objective>
Deploy database schema to remote Supabase, verify Hebrew text handling, test RLS policies, and confirm source attribution structure works correctly.

Purpose: Validate that the database schema handles all Phase 2 requirements: deduplication support, Hebrew text storage without encoding issues, public read access, and multi-platform source tracking.

Output: Verified database schema deployed to production Supabase project with test data confirming Hebrew text and RLS functionality.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-database-core-schema/02-RESEARCH.md
@.planning/phases/02-database-core-schema/02-01-SUMMARY.md
@src/lib/supabase.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Deploy schema to Supabase and verify with test data</name>
  <files></files>
  <action>
    **1. Link to remote Supabase project:**

    Run `supabase link --project-ref [PROJECT_REF_ID]` where PROJECT_REF_ID comes from Supabase Dashboard -> Project Settings -> General -> Reference ID.

    This will prompt for database password. Use the password from Supabase Dashboard -> Project Settings -> Database -> Database password (or reset it if needed).

    **2. Push migration to remote:**

    Run `supabase db push` to apply the migration file to the remote database. This executes the `create_core_schema.sql` migration.

    Verify success: `supabase migration list` should show the migration with status "Applied".

    **3. Verify tables exist:**

    Run `supabase db diff` to check for any schema drift (should be empty).

    Check tables via SQL query:
    ```bash
    supabase db execute "SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name IN ('listings', 'dedupe_hashes');"
    ```

    Should return both table names.

    **4. Verify RLS is enabled:**

    Run SQL query to check RLS status:
    ```bash
    supabase db execute "SELECT tablename, rowsecurity FROM pg_tables WHERE schemaname = 'public' AND tablename IN ('listings', 'dedupe_hashes');"
    ```

    Both tables should show `rowsecurity = t` (true).

    **5. Test Hebrew text insertion and retrieval:**

    Insert test listing with Hebrew text using service_role key:
    ```bash
    # Create a temporary test script
    cat > /tmp/test_hebrew.sql << 'EOF'
    INSERT INTO public.listings (address, city, price, rooms, size_sqm, floor, photos, sources, description)
    VALUES (
      'רחוב הרצל 42',
      'תל אביב',
      5500,
      3.5,
      85,
      2,
      '["https://example.com/photo1.jpg"]'::jsonb,
      '[{"platform": "yad2", "url": "https://yad2.co.il/test", "scraped_at": "2026-02-13T10:00:00Z"}]'::jsonb,
      'דירה מרווחת בלב העיר עם מרפסת גדולה'
    );

    SELECT address, city, description FROM public.listings WHERE city = 'תל אביב';
    EOF

    supabase db execute --file /tmp/test_hebrew.sql
    ```

    Verify the SELECT output shows Hebrew text correctly (רחוב הרצל 42, תל אביב, דירה מרווחת...). No encoding corruption like mojibake characters.

    **6. Test dedupe_hashes insertion:**

    Insert corresponding hash:
    ```bash
    cat > /tmp/test_dedupe.sql << 'EOF'
    INSERT INTO public.dedupe_hashes (listing_id, content_hash)
    SELECT id, 'a' || lpad(md5(random()::text)::text, 63, '0')
    FROM public.listings
    WHERE city = 'תל אביב'
    LIMIT 1;

    SELECT content_hash FROM public.dedupe_hashes;
    EOF

    supabase db execute --file /tmp/test_dedupe.sql
    ```

    Verify hash is stored (64-character string starting with 'a').

    **7. Test multi-source JSONB structure:**

    Insert a listing with multiple sources:
    ```bash
    cat > /tmp/test_multi_source.sql << 'EOF'
    INSERT INTO public.listings (address, city, price, rooms, sources)
    VALUES (
      'שדרות רוטשילד 15',
      'תל אביב',
      7200,
      4,
      '[
        {"platform": "yad2", "url": "https://yad2.co.il/test1", "scraped_at": "2026-02-13T10:00:00Z"},
        {"platform": "homeless", "url": "https://homeless.co.il/test1", "scraped_at": "2026-02-13T11:00:00Z"}
      ]'::jsonb
    );

    SELECT address, jsonb_array_length(sources) as source_count, sources
    FROM public.listings
    WHERE address = 'שדרות רוטשילד 15';
    EOF

    supabase db execute --file /tmp/test_multi_source.sql
    ```

    Verify source_count = 2 and sources array contains both platforms.

    **8. Clean up test data:**

    ```bash
    cat > /tmp/cleanup.sql << 'EOF'
    DELETE FROM public.listings WHERE city = 'תל אביב' AND address IN ('רחוב הרצל 42', 'שדרות רוטשילד 15');
    EOF

    supabase db execute --file /tmp/cleanup.sql
    ```

    All operations above use service_role credentials (full access). Supabase CLI uses service_role by default when linked.
  </action>
  <verify>
    - Run `supabase migration list` and confirm migration status is "Applied"
    - Run `supabase db diff` and confirm output is empty (no drift)
    - Verify Hebrew text SELECT output showed correct characters (no corruption)
    - Verify dedupe_hashes row inserted successfully
    - Verify multi-source listing showed source_count = 2
    - Verify cleanup DELETE removed test data
  </verify>
  <done>
    Migration is deployed to remote Supabase, Hebrew text storage confirmed working, RLS enabled, dedupe_hashes table functional, multi-source JSONB structure validated. Test data cleaned up.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Verify schema deployment and RLS policies</name>
  <what-built>
    Database schema deployed to Supabase with:
    - listings table (all required fields including Hebrew text support)
    - dedupe_hashes table (with foreign key to listings)
    - RLS policies (public read-only access)
    - Indexes (city, price, created_at, sources)
    - Updated_at trigger
    - Hebrew text verified working (UTF-8 storage/retrieval)
    - Multi-platform source attribution tested
  </what-built>
  <how-to-verify>
    **1. Verify via Supabase Dashboard:**

    - Navigate to: https://supabase.com/dashboard/project/[PROJECT_REF]/editor
    - Table Editor: Confirm "listings" and "dedupe_hashes" tables appear in left sidebar
    - Click "listings" table: Verify columns exist (address, city, price, rooms, size_sqm, floor, photos, sources, description, contact_info, created_at, updated_at)
    - Click "dedupe_hashes" table: Verify columns exist (id, listing_id, content_hash, created_at)
    - Click RLS tab: Confirm both tables show "RLS enabled" with 1 policy each (public read)

    **2. Verify RLS read access from frontend:**

    Create a temporary test file to verify anon key read access works:

    ```bash
    cat > /tmp/test_rls.js << 'EOF'
    import { supabase } from './src/lib/supabase.ts'

    async function testReadAccess() {
      // Try to SELECT with anon key (should succeed)
      const { data, error } = await supabase
        .from('listings')
        .select('*')
        .limit(1)

      if (error) {
        console.error('READ FAILED (RLS blocking?):', error)
      } else {
        console.log('READ SUCCESS - RLS allows anon SELECT')
      }

      // Try to INSERT with anon key (should fail)
      const { error: writeError } = await supabase
        .from('listings')
        .insert({ address: 'test', city: 'test', price: 1000 })

      if (writeError) {
        console.log('WRITE BLOCKED - RLS correctly prevents anon INSERT')
      } else {
        console.error('WRITE SUCCEEDED - RLS is broken!')
      }
    }

    testReadAccess()
    EOF
    ```

    Run the test (adjust import path if needed for Node vs browser environment).

    **Expected results:**
    - SELECT succeeds (even if no data, no RLS error)
    - INSERT fails with RLS/permission error

    **3. Visual check:**

    - Tables visible in Supabase Dashboard Table Editor
    - RLS shows "enabled" with policies listed
    - No migration errors in dashboard

    **4. Report findings:**

    Type "approved" if all checks pass, or describe any issues encountered.
  </how-to-verify>
  <resume-signal>Type "approved" or describe issues</resume-signal>
</task>

</tasks>

<verification>
After completing all tasks:
1. Migration is applied to remote Supabase (visible in dashboard)
2. Both tables exist with correct schemas
3. RLS is enabled on both tables
4. Public read policies work (anon key can SELECT)
5. Service role can write (verified via test insertion)
6. Hebrew text stores and retrieves without corruption
7. JSONB sources array handles multiple platforms correctly
8. Foreign key constraint links dedupe_hashes to listings
9. Updated_at trigger exists on listings table
</verification>

<success_criteria>
**Measurable completion:**
1. `supabase migration list` shows migration as "Applied"
2. `supabase db diff` returns empty (no schema drift)
3. Hebrew test data inserted and retrieved without encoding issues
4. Multi-source JSONB tested with 2+ platforms in sources array
5. RLS verification confirms anon SELECT works, anon INSERT fails
6. Supabase Dashboard shows both tables with RLS enabled
7. All test data cleaned up from database
</success_criteria>

<output>
After completion, create `.planning/phases/02-database-core-schema/02-02-SUMMARY.md` documenting:
- Deployment verification results
- Hebrew text test results (confirm no encoding corruption)
- RLS test results (anon read success, anon write blocked)
- Multi-source JSONB structure validation
- Any issues encountered and resolutions
- Database state (tables, policies, triggers confirmed active)
</output>
